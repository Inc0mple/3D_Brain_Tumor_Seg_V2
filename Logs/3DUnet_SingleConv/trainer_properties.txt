device:cuda
display_plot:True
net:UNet3dSingleConv(
  (conv): DoubleConv(
    (double_conv): Sequential(
      (0): Conv3d(4, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (1): GroupNorm(8, 24, eps=1e-05, affine=True)
      (2): ReLU(inplace=True)
      (3): Conv3d(24, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (4): GroupNorm(8, 24, eps=1e-05, affine=True)
      (5): ReLU(inplace=True)
    )
  )
  (enc1): Down(
    (encoder): Sequential(
      (0): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (1): SingleConv(
        (single_conv): Sequential(
          (0): Conv3d(24, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (1): GroupNorm(8, 48, eps=1e-05, affine=True)
          (2): ReLU(inplace=True)
        )
      )
    )
  )
  (enc2): Down(
    (encoder): Sequential(
      (0): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (1): SingleConv(
        (single_conv): Sequential(
          (0): Conv3d(48, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (1): GroupNorm(8, 96, eps=1e-05, affine=True)
          (2): ReLU(inplace=True)
        )
      )
    )
  )
  (enc3): Down(
    (encoder): Sequential(
      (0): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (1): SingleConv(
        (single_conv): Sequential(
          (0): Conv3d(96, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (1): GroupNorm(8, 192, eps=1e-05, affine=True)
          (2): ReLU(inplace=True)
        )
      )
    )
  )
  (enc4): Down(
    (encoder): Sequential(
      (0): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (1): SingleConv(
        (single_conv): Sequential(
          (0): Conv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (1): GroupNorm(8, 192, eps=1e-05, affine=True)
          (2): ReLU(inplace=True)
        )
      )
    )
  )
  (dec1): Up(
    (up): Upsample(scale_factor=2.0, mode=trilinear)
    (conv): SingleConv(
      (single_conv): Sequential(
        (0): Conv3d(384, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
        (1): GroupNorm(8, 96, eps=1e-05, affine=True)
        (2): ReLU(inplace=True)
      )
    )
  )
  (dec2): Up(
    (up): Upsample(scale_factor=2.0, mode=trilinear)
    (conv): SingleConv(
      (single_conv): Sequential(
        (0): Conv3d(192, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
        (1): GroupNorm(8, 48, eps=1e-05, affine=True)
        (2): ReLU(inplace=True)
      )
    )
  )
  (dec3): Up(
    (up): Upsample(scale_factor=2.0, mode=trilinear)
    (conv): SingleConv(
      (single_conv): Sequential(
        (0): Conv3d(96, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
        (1): GroupNorm(8, 24, eps=1e-05, affine=True)
        (2): ReLU(inplace=True)
      )
    )
  )
  (dec4): Up(
    (up): Upsample(scale_factor=2.0, mode=trilinear)
    (conv): SingleConv(
      (single_conv): Sequential(
        (0): Conv3d(48, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
        (1): GroupNorm(8, 24, eps=1e-05, affine=True)
        (2): ReLU(inplace=True)
      )
    )
  )
  (out): Out(
    (conv): Conv3d(24, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1))
  )
)
criterion:BCEDiceLoss(
  (bce): BCEWithLogitsLoss()
  (dice): DiceLoss()
)
optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: False
    lr: 5e-06
    maximize: False
    weight_decay: 0
)
scheduler:<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7f4877827bb0>
accumulation_steps:4
phases:['train', 'val']
num_epochs:50
dataloaders:{'train': <torch.utils.data.dataloader.DataLoader object at 0x7f48709d94c0>, 'val': <torch.utils.data.dataloader.DataLoader object at 0x7f48709d9be0>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f48709d9370>}
best_loss:0.17182014770102952
losses:{'train': [1.4061473213674451, 1.2513753724188859, 1.1400977350459807, 1.0429353104344792, 0.946708330863329, 0.8475541631078539, 0.7280530381112045, 0.5810438869343965, 0.4596159195831973, 0.3782813490683588, 0.3291257691247382, 0.28548303144512976, 0.26600263043954797, 0.253055714495735, 0.2379735489818533, 0.22870484578065545, 0.2192233692387211, 0.20741883846630163, 0.20124500060716055, 0.20256090351157316, 0.19003392843805791, 0.19772151415678937, 0.19729516176443138, 0.17439598998076108, 0.16541578952123911, 0.16295019746846573, 0.16065357646731368, 0.1592743402424874, 0.1581036713356754, 0.1565529853105545, 0.15528394192627173, 0.15389616764770261, 0.15308785057509808, 0.1521869059581267, 0.15158797681558267, 0.15008714463660924, 0.14892549758968243, 0.148745451632448, 0.1483522213202239, 0.14557444350971016, 0.14473534987339956, 0.14455586979201085, 0.1444137730554256, 0.1442813943122503, 0.14416321280621303, 0.1440317240249748, 0.14396519456129564, 0.14384331623580973, 0.14379713484599563, 0.14363558543668953], 'val': [1.3160736200944432, 1.194116032348489, 1.090917022723072, 0.9967884747487195, 0.9001776722242247, 0.7859217816928648, 0.6573999169862496, 0.5202122072003922, 0.4189389114672283, 0.37427821642947645, 0.3135238956168013, 0.30118843603808926, 0.24666685962452078, 0.23967837500122358, 0.26015994458828334, 0.2208547294139862, 0.22047676047626533, 0.22211300286481966, 0.19685496347692777, 0.1958592046263083, 0.1980050178068989, 0.25539919466904876, 0.1982521209514366, 0.1827533077800049, 0.18130443891826667, 0.18138865212786873, 0.18135568204353442, 0.17883462964926125, 0.17927163740936317, 0.1778878575226046, 0.17744570492573505, 0.1750744513745578, 0.17438820046636294, 0.17571761993304738, 0.17419902600769727, 0.17278713648611643, 0.17394451037892755, 0.17494245421773982, 0.17453499686605525, 0.1722311166659841, 0.17227518544444498, 0.172242856250619, 0.17208884965698673, 0.1721506873672863, 0.17202774111954672, 0.17199118435382843, 0.17201796708241948, 0.1721393217174512, 0.17182014770102952, 0.17186026457908019]}
dice_scores:{'train': [0.34145555, 0.59332246, 0.6143988, 0.618714, 0.61604375, 0.609227, 0.64178073, 0.71647537, 0.7522225, 0.7654716, 0.7768769, 0.79623204, 0.7993245, 0.8034108, 0.8104462, 0.81504375, 0.8192926, 0.82800514, 0.8321227, 0.82835203, 0.8380982, 0.830071, 0.8293777, 0.8502011, 0.8579156, 0.8601226, 0.8621563, 0.8633867, 0.8643121, 0.8656991, 0.8668839, 0.8679479, 0.8687055, 0.8695256, 0.8698826, 0.8712321, 0.87236476, 0.8722486, 0.8723806, 0.87515587, 0.8759418, 0.87606454, 0.8761721, 0.8762877, 0.8763706, 0.8765174, 0.8765195, 0.87671316, 0.8766971, 0.87684417], 'val': [0.46707687, 0.54339576, 0.6190173, 0.6398908, 0.6612538, 0.6282942, 0.691141, 0.7202805, 0.7304522, 0.7313967, 0.7746925, 0.76467824, 0.8106491, 0.8091075, 0.7837783, 0.8167735, 0.81429905, 0.81150407, 0.83225983, 0.83271533, 0.82758325, 0.77418834, 0.8282775, 0.8406625, 0.8418759, 0.8416961, 0.8414051, 0.8441073, 0.84327155, 0.84455186, 0.84491843, 0.84699696, 0.8477586, 0.8462442, 0.84770215, 0.8490592, 0.8477042, 0.84694356, 0.8471858, 0.8492103, 0.8490459, 0.8491405, 0.84927815, 0.8491937, 0.8492989, 0.84933865, 0.8493022, 0.8491328, 0.8495267, 0.84943974]}
jaccard_scores:{'train': [0.24039075, 0.44238785, 0.45914513, 0.467966, 0.46605635, 0.4565397, 0.49247238, 0.5776874, 0.62022406, 0.6360481, 0.6492443, 0.6733992, 0.6778582, 0.6822864, 0.69168204, 0.69844586, 0.70364654, 0.7153899, 0.72053796, 0.7167234, 0.730556, 0.72185546, 0.71846825, 0.7463678, 0.75701, 0.76011837, 0.7630105, 0.76468986, 0.766065, 0.7681732, 0.7698354, 0.771515, 0.77247554, 0.77378017, 0.7742669, 0.7763814, 0.77798325, 0.7778211, 0.77793926, 0.78214496, 0.7832377, 0.7834561, 0.7836497, 0.7837941, 0.7839344, 0.784139, 0.7841464, 0.7843937, 0.7844727, 0.78463185], 'val': [0.32800972, 0.39462554, 0.4640472, 0.486244, 0.50856906, 0.47304296, 0.5496099, 0.5876049, 0.5906764, 0.59853005, 0.64456975, 0.6359725, 0.6904617, 0.689474, 0.6591176, 0.7005167, 0.6975759, 0.69282085, 0.721403, 0.72167856, 0.7150386, 0.6482151, 0.7174807, 0.7340449, 0.735911, 0.7357191, 0.7352657, 0.73911697, 0.7381504, 0.7398801, 0.74032485, 0.7429644, 0.7441285, 0.7420111, 0.7444079, 0.74619716, 0.7440885, 0.74343777, 0.74414754, 0.746773, 0.7465086, 0.74662787, 0.7468162, 0.74668884, 0.7468531, 0.7469145, 0.7468758, 0.7466523, 0.74716616, 0.7470644]}
last_completed_run_time:5:34:36.332869
parameter_count:3006507
