device:cuda
display_plot:True
net:UNet3dDropout(
  (conv): DoubleConv(
    (double_conv): Sequential(
      (0): Conv3d(4, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (1): GroupNorm(8, 24, eps=1e-05, affine=True)
      (2): Dropout(p=0.2, inplace=False)
      (3): ReLU(inplace=True)
      (4): Conv3d(24, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (5): GroupNorm(8, 24, eps=1e-05, affine=True)
      (6): Dropout(p=0.2, inplace=False)
      (7): ReLU(inplace=True)
    )
  )
  (enc1): Down(
    (encoder): Sequential(
      (0): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (1): DoubleConv(
        (double_conv): Sequential(
          (0): Conv3d(24, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (1): GroupNorm(8, 48, eps=1e-05, affine=True)
          (2): Dropout(p=0.2, inplace=False)
          (3): ReLU(inplace=True)
          (4): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (5): GroupNorm(8, 48, eps=1e-05, affine=True)
          (6): Dropout(p=0.2, inplace=False)
          (7): ReLU(inplace=True)
        )
      )
    )
  )
  (enc2): Down(
    (encoder): Sequential(
      (0): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (1): DoubleConv(
        (double_conv): Sequential(
          (0): Conv3d(48, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (1): GroupNorm(8, 96, eps=1e-05, affine=True)
          (2): Dropout(p=0.2, inplace=False)
          (3): ReLU(inplace=True)
          (4): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (5): GroupNorm(8, 96, eps=1e-05, affine=True)
          (6): Dropout(p=0.2, inplace=False)
          (7): ReLU(inplace=True)
        )
      )
    )
  )
  (enc3): Down(
    (encoder): Sequential(
      (0): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (1): DoubleConv(
        (double_conv): Sequential(
          (0): Conv3d(96, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (1): GroupNorm(8, 192, eps=1e-05, affine=True)
          (2): Dropout(p=0.2, inplace=False)
          (3): ReLU(inplace=True)
          (4): Conv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (5): GroupNorm(8, 192, eps=1e-05, affine=True)
          (6): Dropout(p=0.2, inplace=False)
          (7): ReLU(inplace=True)
        )
      )
    )
  )
  (enc4): Down(
    (encoder): Sequential(
      (0): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (1): DoubleConv(
        (double_conv): Sequential(
          (0): Conv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (1): GroupNorm(8, 192, eps=1e-05, affine=True)
          (2): Dropout(p=0.2, inplace=False)
          (3): ReLU(inplace=True)
          (4): Conv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (5): GroupNorm(8, 192, eps=1e-05, affine=True)
          (6): Dropout(p=0.2, inplace=False)
          (7): ReLU(inplace=True)
        )
      )
    )
  )
  (dec1): Up(
    (up): Upsample(scale_factor=2.0, mode=trilinear)
    (conv): DoubleConv(
      (double_conv): Sequential(
        (0): Conv3d(384, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
        (1): GroupNorm(8, 96, eps=1e-05, affine=True)
        (2): Dropout(p=0.2, inplace=False)
        (3): ReLU(inplace=True)
        (4): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
        (5): GroupNorm(8, 96, eps=1e-05, affine=True)
        (6): Dropout(p=0.2, inplace=False)
        (7): ReLU(inplace=True)
      )
    )
  )
  (dec2): Up(
    (up): Upsample(scale_factor=2.0, mode=trilinear)
    (conv): DoubleConv(
      (double_conv): Sequential(
        (0): Conv3d(192, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
        (1): GroupNorm(8, 48, eps=1e-05, affine=True)
        (2): Dropout(p=0.2, inplace=False)
        (3): ReLU(inplace=True)
        (4): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
        (5): GroupNorm(8, 48, eps=1e-05, affine=True)
        (6): Dropout(p=0.2, inplace=False)
        (7): ReLU(inplace=True)
      )
    )
  )
  (dec3): Up(
    (up): Upsample(scale_factor=2.0, mode=trilinear)
    (conv): DoubleConv(
      (double_conv): Sequential(
        (0): Conv3d(96, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
        (1): GroupNorm(8, 24, eps=1e-05, affine=True)
        (2): Dropout(p=0.2, inplace=False)
        (3): ReLU(inplace=True)
        (4): Conv3d(24, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
        (5): GroupNorm(8, 24, eps=1e-05, affine=True)
        (6): Dropout(p=0.2, inplace=False)
        (7): ReLU(inplace=True)
      )
    )
  )
  (dec4): Up(
    (up): Upsample(scale_factor=2.0, mode=trilinear)
    (conv): DoubleConv(
      (double_conv): Sequential(
        (0): Conv3d(48, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
        (1): GroupNorm(8, 24, eps=1e-05, affine=True)
        (2): Dropout(p=0.2, inplace=False)
        (3): ReLU(inplace=True)
        (4): Conv3d(24, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
        (5): GroupNorm(8, 24, eps=1e-05, affine=True)
        (6): Dropout(p=0.2, inplace=False)
        (7): ReLU(inplace=True)
      )
    )
  )
  (out): Out(
    (conv): Conv3d(24, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1))
  )
)
criterion:BCEDiceLoss(
  (bce): BCEWithLogitsLoss()
  (dice): DiceLoss()
)
optimizer:AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    eps: 1e-08
    foreach: None
    lr: 5.000000000000001e-07
    maximize: False
    weight_decay: 0.01
)
scheduler:<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7fae26a6d0a0>
accumulation_steps:4
phases:['train', 'val']
num_epochs:50
dataloaders:{'train': <torch.utils.data.dataloader.DataLoader object at 0x7fae26ba28b0>, 'val': <torch.utils.data.dataloader.DataLoader object at 0x7fae26ba2ca0>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7fae26ba2e20>}
best_loss:0.19017942158399886
losses:{'train': [1.392329511533672, 1.2525321091082613, 1.1479126777032482, 1.0652347537954496, 0.9924442101794051, 0.9171755948447456, 0.83023281265121, 0.7335804611331156, 0.6218846121894996, 0.5151211154778194, 0.43528377369556137, 0.37462358437336896, 0.35260995786226296, 0.31835462968838985, 0.29497421518704736, 0.28115461319118396, 0.27807689480795156, 0.32772408530626007, 0.2707365076181553, 0.25124817106433694, 0.23577605643993094, 0.22988975736464837, 0.21514474937671038, 0.21467266152453512, 0.21597423543268285, 0.21795347712565738, 0.21149362125097573, 0.19566450270863087, 0.1915055379668116, 0.19045391588156668, 0.18974805181357343, 0.18867692028388325, 0.18729386501325854, 0.18704434742039147, 0.18607597259854183, 0.18494042788168324, 0.18440493003610423, 0.18321451080162715, 0.18349441721638798, 0.18233636021614075, 0.18201548835623854, 0.18043227888955363, 0.1798738451398371, 0.17833438947683505, 0.1783609470713728, 0.17804295382685534, 0.17832728366264824, 0.1779306878835076, 0.17808615549435633, 0.17774121658770303], 'val': [1.3018561781577345, 1.1838095660479564, 1.0893698660832531, 1.0097024137119077, 0.9315357208251953, 0.843017262107921, 0.7334390698738817, 0.6272436194824722, 0.49649890470054914, 0.37325178171103857, 0.3169694832473431, 0.2952167403023198, 0.29327977490874957, 0.2609726553255657, 0.2980162615202508, 0.23631707171224198, 0.23163075126566976, 0.24219416095963064, 0.2272835610047826, 0.21559391803336594, 0.22004203849805976, 0.21507538517691055, 0.20760819048814053, 0.19947742220928083, 0.21580323225484704, 0.21397337711082315, 0.211071178176493, 0.1993875783288254, 0.19923822103806263, 0.1984870707932508, 0.1989166518708445, 0.19804873514287877, 0.19727337978920848, 0.19603854333454707, 0.19693223555695336, 0.1962558241244757, 0.19503174300463694, 0.19153011112280613, 0.1915569968943326, 0.190284816653661, 0.1912807453915758, 0.191103939318432, 0.1904972147829128, 0.19045378415370887, 0.19025684183217445, 0.19017942158399886, 0.19040652498040558, 0.19022536263713297, 0.19020062685012817, 0.19020367160720644]}
dice_scores:{'train': [0.20489511, 0.51502496, 0.59156317, 0.5902978, 0.5903923, 0.60333717, 0.6196903, 0.6265527, 0.6695285, 0.7115328, 0.73314416, 0.75564045, 0.74970376, 0.7653484, 0.77572066, 0.7814119, 0.7763419, 0.72307247, 0.77481407, 0.79026765, 0.8029171, 0.80608624, 0.81809133, 0.8167319, 0.8139855, 0.8107474, 0.8158686, 0.83020353, 0.83404714, 0.83496386, 0.83556587, 0.8364554, 0.8376962, 0.8377953, 0.8385808, 0.83956176, 0.8398859, 0.84106106, 0.8406058, 0.84160554, 0.84186965, 0.84330225, 0.8436989, 0.8450468, 0.84505236, 0.84537333, 0.8451074, 0.8454329, 0.84528166, 0.8456058], 'val': [0.56770545, 0.5629043, 0.5732676, 0.61036843, 0.5842047, 0.60393095, 0.64576805, 0.66182804, 0.6895621, 0.7535942, 0.7706353, 0.76789635, 0.75318223, 0.77570516, 0.73643667, 0.7925075, 0.79504114, 0.7822789, 0.795019, 0.804976, 0.7989022, 0.8032616, 0.80969685, 0.8164781, 0.8020869, 0.80275583, 0.8059065, 0.8163254, 0.8166045, 0.81727284, 0.8168362, 0.8176301, 0.81828094, 0.81953406, 0.8186142, 0.8192164, 0.82004625, 0.8233763, 0.8233144, 0.82438517, 0.8233933, 0.82353586, 0.8240415, 0.8240433, 0.82421297, 0.82429886, 0.82406014, 0.8242487, 0.8242558, 0.8242509]}
jaccard_scores:{'train': [0.12356071, 0.3647844, 0.4368437, 0.4365194, 0.43545768, 0.4488592, 0.46515557, 0.47543254, 0.5225514, 0.56975925, 0.5976751, 0.62245184, 0.61646754, 0.63457876, 0.64763445, 0.65376717, 0.64901054, 0.58924747, 0.64623, 0.6674974, 0.6828098, 0.68869483, 0.70341027, 0.7017213, 0.6981304, 0.6937149, 0.7013089, 0.71912867, 0.724598, 0.72583926, 0.72663003, 0.7277792, 0.72926915, 0.7294582, 0.7305538, 0.73171765, 0.7320856, 0.7335465, 0.73290795, 0.7339659, 0.7346115, 0.7366168, 0.7370458, 0.7388285, 0.7389102, 0.7393151, 0.73900217, 0.7393975, 0.7391686, 0.73964244], 'val': [0.41612014, 0.41213164, 0.41914335, 0.45514944, 0.43062055, 0.45015788, 0.49070686, 0.51142824, 0.5466958, 0.62539643, 0.64743596, 0.64191335, 0.6297074, 0.65189004, 0.6060236, 0.67323685, 0.67503005, 0.66140795, 0.67771286, 0.6901262, 0.67998576, 0.68676007, 0.6952944, 0.7020995, 0.68354523, 0.685218, 0.6892588, 0.704038, 0.7048304, 0.7057661, 0.70507824, 0.70637685, 0.7070783, 0.7088456, 0.707517, 0.7086237, 0.7090257, 0.7132901, 0.71306896, 0.71389073, 0.71306634, 0.71344924, 0.7138519, 0.71388763, 0.7141203, 0.71423936, 0.7139673, 0.7142088, 0.7142255, 0.71421444]}
