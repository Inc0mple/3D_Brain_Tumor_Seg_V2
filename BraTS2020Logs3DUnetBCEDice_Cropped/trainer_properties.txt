device:cuda
display_plot:True
net:UNet3d(
  (conv): DoubleConv(
    (double_conv): Sequential(
      (0): Conv3d(4, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (1): GroupNorm(8, 24, eps=1e-05, affine=True)
      (2): Dropout(p=0.2, inplace=False)
      (3): ReLU(inplace=True)
      (4): Conv3d(24, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
      (5): GroupNorm(8, 24, eps=1e-05, affine=True)
      (6): Dropout(p=0.2, inplace=False)
      (7): ReLU(inplace=True)
    )
  )
  (enc1): Down(
    (encoder): Sequential(
      (0): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (1): DoubleConv(
        (double_conv): Sequential(
          (0): Conv3d(24, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (1): GroupNorm(8, 48, eps=1e-05, affine=True)
          (2): Dropout(p=0.2, inplace=False)
          (3): ReLU(inplace=True)
          (4): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (5): GroupNorm(8, 48, eps=1e-05, affine=True)
          (6): Dropout(p=0.2, inplace=False)
          (7): ReLU(inplace=True)
        )
      )
    )
  )
  (enc2): Down(
    (encoder): Sequential(
      (0): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (1): DoubleConv(
        (double_conv): Sequential(
          (0): Conv3d(48, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (1): GroupNorm(8, 96, eps=1e-05, affine=True)
          (2): Dropout(p=0.2, inplace=False)
          (3): ReLU(inplace=True)
          (4): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (5): GroupNorm(8, 96, eps=1e-05, affine=True)
          (6): Dropout(p=0.2, inplace=False)
          (7): ReLU(inplace=True)
        )
      )
    )
  )
  (enc3): Down(
    (encoder): Sequential(
      (0): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (1): DoubleConv(
        (double_conv): Sequential(
          (0): Conv3d(96, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (1): GroupNorm(8, 192, eps=1e-05, affine=True)
          (2): Dropout(p=0.2, inplace=False)
          (3): ReLU(inplace=True)
          (4): Conv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (5): GroupNorm(8, 192, eps=1e-05, affine=True)
          (6): Dropout(p=0.2, inplace=False)
          (7): ReLU(inplace=True)
        )
      )
    )
  )
  (enc4): Down(
    (encoder): Sequential(
      (0): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (1): DoubleConv(
        (double_conv): Sequential(
          (0): Conv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (1): GroupNorm(8, 192, eps=1e-05, affine=True)
          (2): Dropout(p=0.2, inplace=False)
          (3): ReLU(inplace=True)
          (4): Conv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (5): GroupNorm(8, 192, eps=1e-05, affine=True)
          (6): Dropout(p=0.2, inplace=False)
          (7): ReLU(inplace=True)
        )
      )
    )
  )
  (dec1): Up(
    (up): Upsample(scale_factor=2.0, mode=trilinear)
    (conv): DoubleConv(
      (double_conv): Sequential(
        (0): Conv3d(384, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
        (1): GroupNorm(8, 96, eps=1e-05, affine=True)
        (2): Dropout(p=0.2, inplace=False)
        (3): ReLU(inplace=True)
        (4): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
        (5): GroupNorm(8, 96, eps=1e-05, affine=True)
        (6): Dropout(p=0.2, inplace=False)
        (7): ReLU(inplace=True)
      )
    )
  )
  (dec2): Up(
    (up): Upsample(scale_factor=2.0, mode=trilinear)
    (conv): DoubleConv(
      (double_conv): Sequential(
        (0): Conv3d(192, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
        (1): GroupNorm(8, 48, eps=1e-05, affine=True)
        (2): Dropout(p=0.2, inplace=False)
        (3): ReLU(inplace=True)
        (4): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
        (5): GroupNorm(8, 48, eps=1e-05, affine=True)
        (6): Dropout(p=0.2, inplace=False)
        (7): ReLU(inplace=True)
      )
    )
  )
  (dec3): Up(
    (up): Upsample(scale_factor=2.0, mode=trilinear)
    (conv): DoubleConv(
      (double_conv): Sequential(
        (0): Conv3d(96, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
        (1): GroupNorm(8, 24, eps=1e-05, affine=True)
        (2): Dropout(p=0.2, inplace=False)
        (3): ReLU(inplace=True)
        (4): Conv3d(24, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
        (5): GroupNorm(8, 24, eps=1e-05, affine=True)
        (6): Dropout(p=0.2, inplace=False)
        (7): ReLU(inplace=True)
      )
    )
  )
  (dec4): Up(
    (up): Upsample(scale_factor=2.0, mode=trilinear)
    (conv): DoubleConv(
      (double_conv): Sequential(
        (0): Conv3d(48, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
        (1): GroupNorm(8, 24, eps=1e-05, affine=True)
        (2): Dropout(p=0.2, inplace=False)
        (3): ReLU(inplace=True)
        (4): Conv3d(24, 24, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
        (5): GroupNorm(8, 24, eps=1e-05, affine=True)
        (6): Dropout(p=0.2, inplace=False)
        (7): ReLU(inplace=True)
      )
    )
  )
  (out): Out(
    (conv): Conv3d(24, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1))
  )
)
criterion:BCEDiceLoss(
  (bce): BCEWithLogitsLoss()
  (dice): DiceLoss()
)
optimizer:Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: False
    lr: 5.000000000000001e-07
    maximize: False
    weight_decay: 0
)
scheduler:<torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x7f7cf686f490>
accumulation_steps:4
phases:['train', 'val']
num_epochs:50
dataloaders:{'train': <torch.utils.data.dataloader.DataLoader object at 0x7f7cf691cac0>, 'val': <torch.utils.data.dataloader.DataLoader object at 0x7f7cf691cf70>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7f7cf691c5b0>}
best_loss:0.13803341331065827
losses:{'train': [1.3694679578447524, 1.219277287164115, 1.1083859243773688, 1.0110885267475258, 0.907407102929322, 0.7842823067545438, 0.6499225620761118, 0.5148039540070545, 0.4067084252154419, 0.32928751369392917, 0.2746034962879388, 0.24462080511756723, 0.2213351131618703, 0.214818473012955, 0.20025490866017887, 0.1887787248755136, 0.18639723473572006, 0.17947302601466614, 0.17854035985673788, 0.1643300957042908, 0.1661874379240288, 0.16055946975606475, 0.1524980912558706, 0.15163419595406083, 0.1489432342633775, 0.1480553666335095, 0.1438515922869113, 0.14061139543813445, 0.13501417852173286, 0.12992421571632756, 0.12821596688077477, 0.12786564735178713, 0.12661267379334218, 0.12542787199917854, 0.12538203827951797, 0.12455541861487886, 0.12420128617336541, 0.12342022882044995, 0.1229110585504385, 0.12244579846131484, 0.12256524271328187, 0.12160031884172116, 0.12064804752913265, 0.12029298950170836, 0.11940847413734791, 0.11866647738807555, 0.11733375304155477, 0.11686698928078772, 0.11691031612087566, 0.11677992608780643], 'val': [1.2672997443181164, 1.1448288931036896, 1.0368969822829623, 0.9308296397047223, 0.8063735309636818, 0.6575515388317827, 0.5039892483432338, 0.38499077339217347, 0.28458142589847996, 0.23522194966955004, 0.2164029618198017, 0.21127000015299274, 0.20624696041615503, 0.1887750286116915, 0.20938248946419302, 0.19545198021070012, 0.17350659013356803, 0.16608687525369087, 0.16782362393613132, 0.16164385766353248, 0.18762617122452213, 0.15581667542738734, 0.15719737527224253, 0.15518354336326978, 0.1469607692703886, 0.15073864977314788, 0.16891840388471224, 0.17051148864458193, 0.14451233571711578, 0.14410761336110672, 0.14353519291529115, 0.1439731868932832, 0.14129449483358636, 0.14142003838183745, 0.14108357944016187, 0.14037864725544769, 0.13983696530450065, 0.13901281181090283, 0.14066193344176942, 0.13881941413823165, 0.13812325100572603, 0.1385186140970239, 0.13804106674385522, 0.13950999235769487, 0.14873947765467302, 0.13915835827026726, 0.13803341331065827, 0.13834777453316832, 0.13822132848062604, 0.13826029016724173]}
dice_scores:{'train': [0.39833778, 0.67389655, 0.7392125, 0.7544408, 0.75770587, 0.79614514, 0.79294336, 0.8080419, 0.8210646, 0.8334889, 0.8465759, 0.8501261, 0.8554348, 0.850601, 0.85549474, 0.86157364, 0.8588736, 0.8615602, 0.85983795, 0.870455, 0.86677384, 0.8708406, 0.87683547, 0.8766548, 0.8778061, 0.8778677, 0.88085693, 0.88324666, 0.88795364, 0.89242053, 0.89391404, 0.8941535, 0.8952779, 0.8962971, 0.89611804, 0.89695364, 0.8970822, 0.89789003, 0.898142, 0.89845794, 0.89832586, 0.89899236, 0.8998153, 0.90004253, 0.9006317, 0.9012593, 0.90237236, 0.9027493, 0.90267897, 0.9028243], 'val': [0.6977324, 0.69889766, 0.72569835, 0.7882203, 0.7912195, 0.7925331, 0.8164964, 0.8209975, 0.8279595, 0.839501, 0.83746016, 0.8327904, 0.8276776, 0.84034276, 0.822947, 0.83119315, 0.8493522, 0.85569, 0.8539541, 0.85780764, 0.83476555, 0.8627189, 0.86064243, 0.86204064, 0.87015945, 0.8664344, 0.849672, 0.847411, 0.87149113, 0.8716977, 0.8721009, 0.8716962, 0.8743566, 0.87384635, 0.87411386, 0.8748866, 0.87548614, 0.87599087, 0.8744653, 0.87628067, 0.87664664, 0.87637407, 0.8767759, 0.87530184, 0.86716866, 0.8756678, 0.87664235, 0.8763054, 0.87644, 0.87640125]}
jaccard_scores:{'train': [0.2801673, 0.53932256, 0.6172962, 0.63347507, 0.639111, 0.68338025, 0.6835718, 0.7015304, 0.71505785, 0.7306068, 0.7490371, 0.75300705, 0.76061445, 0.754879, 0.7617679, 0.76748383, 0.76446354, 0.76967376, 0.7659619, 0.78064746, 0.7773798, 0.7821689, 0.79013866, 0.78910625, 0.79117924, 0.79143226, 0.7954626, 0.79896766, 0.8060856, 0.8125315, 0.81454605, 0.8149168, 0.81642646, 0.8178333, 0.8174226, 0.8185564, 0.81880033, 0.82000476, 0.8204878, 0.82081693, 0.8205207, 0.8215328, 0.8228251, 0.8229524, 0.82379174, 0.8248053, 0.82648474, 0.8269925, 0.8268688, 0.8271272], 'val': [0.56920385, 0.5709658, 0.59988153, 0.6767563, 0.6811676, 0.6825472, 0.7115357, 0.71451527, 0.72074467, 0.74073225, 0.73965406, 0.72907305, 0.73029464, 0.74515676, 0.71381825, 0.73415905, 0.75378245, 0.7602303, 0.75569123, 0.7629604, 0.7310882, 0.7684748, 0.769, 0.77156687, 0.77890986, 0.77485144, 0.751266, 0.74811757, 0.7808953, 0.7815492, 0.7822369, 0.7816218, 0.7851992, 0.78480333, 0.7851752, 0.7864823, 0.7869894, 0.78795946, 0.7856635, 0.7883626, 0.7889499, 0.78862596, 0.78920376, 0.7870437, 0.77541983, 0.787679, 0.7890121, 0.78853434, 0.7887173, 0.7886675]}
